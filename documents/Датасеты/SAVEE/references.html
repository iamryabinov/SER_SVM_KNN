<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0072)http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/References.html -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><!-- InstanceBegin template="/Templates/No Sidebars.dwt" codeOutsideHTMLIsLocked="false" --><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1251">
<!-- InstanceBeginEditable name="doctitle" -->
<title>Surrey Audio-Visual Expressed Emotion (SAVEE) Database</title>
<meta name="Description" content="Surrey Audio-Visual Expressed Emotion (SAVEE) Database">
<meta name="Keywords" content="SAVEE, audio-visual, multimodal, emotion, expression, affect, affective, classification, recognition, database">
<meta name="content-language" content="en-GB">
<link rel="icon" href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/images/FaceJK_icon.png" type="image/png">
<!-- InstanceEndEditable -->
<link href="./references_files/style.css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="./references_files/jquery.min.js.Без названия"></script>
<script type="text/javascript" src="./references_files/hoverIntent.js.Без названия"></script>
<script type="text/javascript" src="./references_files/superfish.js.Без названия"></script>
<script type="text/javascript" src="./references_files/supersubs.js.Без названия"></script>
<script type="text/javascript"> 
    $(document).ready(function(){ 
        $("ul.sf-menu").supersubs({ 
            minWidth:    12,   // minimum width of sub-menus in em units 
            maxWidth:    27,   // maximum width of sub-menus in em units 
            extraWidth:  1     // extra width can ensure lines don't sometimes turn over 
                               // due to slight rounding differences and font-family 
        }).superfish();  // call supersubs first, then superfish, so that subs are 
                         // not display:none when measuring. Call before initialising 
                         // containing tabs for same reason. 
    }); 
</script>
<!-- InstanceBeginEditable name="head" -->
<!-- InstanceEndEditable -->
<style>._3emE9--dark-theme .-S-tR--ff-downloader{background:rgba(30,30,30,.93);border:1px solid rgba(82,82,82,.54);box-shadow:0 4px 7px rgba(30,30,30,.55);color:#fff}._3emE9--dark-theme .-S-tR--ff-downloader ._6_Mtt--header ._2VdJW--minimize-btn{background:#3d4b52}._3emE9--dark-theme .-S-tR--ff-downloader ._6_Mtt--header ._2VdJW--minimize-btn:hover{background:#131415}._3emE9--dark-theme .-S-tR--ff-downloader ._10vpG--footer{background:rgba(30,30,30,.93)}._2mDEx--white-theme .-S-tR--ff-downloader{background:#fff;border:1px solid rgba(82,82,82,.54);box-shadow:0 4px 7px rgba(30,30,30,.55);color:#314c75}._2mDEx--white-theme .-S-tR--ff-downloader ._6_Mtt--header{font-weight:700}._2mDEx--white-theme .-S-tR--ff-downloader ._2dFLA--container ._2bWNS--notice{border:0;color:rgba(0,0,0,.88)}._2mDEx--white-theme .-S-tR--ff-downloader ._10vpG--footer{background:#fff}.-S-tR--ff-downloader{display:block;overflow:hidden;position:fixed;bottom:20px;right:7.1%;width:330px;height:180px;background:rgba(30,30,30,.93);border-radius:2px;color:#fff;z-index:99999999;border:1px solid rgba(82,82,82,.54);box-shadow:0 4px 7px rgba(30,30,30,.55);transition:.5s}.-S-tR--ff-downloader._3M7UQ--minimize{height:62px}.-S-tR--ff-downloader._3M7UQ--minimize .nxuu4--file-info,.-S-tR--ff-downloader._3M7UQ--minimize ._6_Mtt--header{display:none}.-S-tR--ff-downloader ._6_Mtt--header{padding:10px;font-size:17px;font-family:sans-serif}.-S-tR--ff-downloader ._6_Mtt--header ._2VdJW--minimize-btn{float:right;background:#f1ecec;height:20px;width:20px;text-align:center;padding:2px;margin-top:-10px;cursor:pointer}.-S-tR--ff-downloader ._6_Mtt--header ._2VdJW--minimize-btn:hover{background:#e2dede}.-S-tR--ff-downloader ._13XQ2--error{color:red;padding:10px;font-size:12px;line-height:19px}.-S-tR--ff-downloader ._2dFLA--container{position:relative;height:100%}.-S-tR--ff-downloader ._2dFLA--container .nxuu4--file-info{padding:6px 15px 0;font-family:sans-serif}.-S-tR--ff-downloader ._2dFLA--container .nxuu4--file-info div{margin-bottom:5px;width:100%;overflow:hidden}.-S-tR--ff-downloader ._2dFLA--container ._2bWNS--notice{margin-top:21px;font-size:11px}.-S-tR--ff-downloader ._10vpG--footer{width:100%;bottom:0;position:absolute;font-weight:700}.-S-tR--ff-downloader ._10vpG--footer ._2V73d--loader{-webkit-animation:n0BD1--rotation 3.5s linear forwards;animation:n0BD1--rotation 3.5s linear forwards;position:absolute;top:-120px;left:calc(50% - 35px);border-radius:50%;border:5px solid #fff;border-top-color:#a29bfe;height:70px;width:70px;display:flex;justify-content:center;align-items:center}.-S-tR--ff-downloader ._10vpG--footer ._24wjw--loading-bar{width:100%;height:18px;background:#dfe6e9;border-radius:5px}.-S-tR--ff-downloader ._10vpG--footer ._24wjw--loading-bar ._1FVu9--progress-bar{height:100%;background:#8bc34a;border-radius:5px}.-S-tR--ff-downloader ._10vpG--footer ._2KztS--status{margin-top:10px}.-S-tR--ff-downloader ._10vpG--footer ._2KztS--status ._1XilH--state{float:left;font-size:.9em;letter-spacing:1pt;text-transform:uppercase;width:100px;height:20px;position:relative}.-S-tR--ff-downloader ._10vpG--footer ._2KztS--status ._1jiaj--percentage{float:right}</style></head>
<body>
<div id="nav" class="container_12 rounded" style="text-align:center;">

<font size="+3"><font color="white">Surrey Audio-Visual Expressed Emotion (SAVEE) Database</font></font>
</div>

<div id="nav" class="container_12 rounded">
  <ul class="sf-menu sf-js-enabled sf-shadow">
    <li class="first-item"><a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/" style="border-left:none;">Home</a> </li>
    <li>  <a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/Introduction.html">Introduction</a>   </li>
    <li> <a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/Database.html">Database</a> </li>
    <li> <a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/Evaluation.html">Evaluation</a> </li>
    <li> <a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/References.html">References</a> </li>
    <li> <a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/Download.html">Download</a> </li>
  </ul>
</div>

<div id="content" class="container_12 rounded">

  
  <div class="grid_12"><!-- InstanceBeginEditable name=&quot;MainContent&quot; -->
     <h2><font color="blue">Publications</font></h2>
    <p>The SAVEE database was recorded as part of an investigation into audio-visual emotion classification, from which the following articles have been published:
</p><table border="0">  
<tbody><tr valign="top">
<td>•&nbsp;&nbsp;</td><td>S. Haq and P.J.B. Jackson, "Multimodal Emotion Recognition", In W. Wang (ed), Machine Audition: Principles, Algorithms and Systems, IGI Global Press, ISBN 978-1615209194, chapter 17, pp. 398-423, 2010.
[&nbsp;<a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/ma10/HaqJackson_MachineAudition10.bib">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.4018/978-1-61520-919-4">doi</a>&nbsp;| 
<a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/ma10/HaqJackson_MachineAudition10_approved.pdf">pdf</a>&nbsp;]
<!-- <A HREF="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/ma10/HaqJackson_MachineAudition10_ch17.pdf"></A>preprint&nbsp; -->
</td>
</tr>
<tr valign="top">
<td>•&nbsp;&nbsp;</td><td>S. Haq and P.J.B. Jackson. "Speaker-Dependent Audio-Visual Emotion Recognition",
In Proc. Int'l Conf. on Auditory-Visual Speech Processing, pages 53-58,
2009.
[&nbsp;<a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/avsp09/HaqJackson_AVSP09.bib">bib</a>&nbsp;| 
<a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/avsp09/HaqJackson_AVSP09.pdf">preprint</a>&nbsp;| 
<a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/avsp09/HaqJackson_AVSP09_talk.pdf">slides</a>&nbsp;]
</td>
</tr>
<tr valign="top">
<td>•&nbsp;&nbsp;</td><td>S. Haq, P.J.B. Jackson, and J.D. Edge. Audio-Visual Feature Selection and
Reduction for Emotion Classification. In Proc. Int'l Conf. on Auditory-Visual
Speech Processing, pages 185-190, 2008.
[&nbsp;<a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/avsp08/HaqEtAl_AVSP08.bib">bib</a>&nbsp;| <a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/avsp08/HaqJacksonEdge_AVSP08.pdf">preprint</a>&nbsp;]
</td>
</tr>
</tbody></table>
<p></p>

    <hr>

    <h2><font color="blue">References</font></h2>
    <p>[1] Sebe, N., et al., "Multimodal Emotion Recognition", Handbook
of Pattern Recog. and Computer Vision, World Scientific, 2005. <br>
[2] Batliner, A., et al., "You Stupid Tin Box-Children Interacting with
the AIBO Robot: A Cross-Linguistic Emotional Speech", Proc.
Int'l Conf. Lang. Resources and Evaluation,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;171-174, 2004. <br>
[3] Burkhardt, F., et al., "A Database of German Emotional Speech",
Proc. Interspeech, 1517-1520, 2005. <br>
[4] Engberg, I.S., et al., "Documentation of the Danish Emotional
Speech Database (DES)", Aalborg University, Denmark, 1996. <br>
[5] Kanade, T., Cohn, J. and Tian, Y., "Comprehensive Database for
Facial Expression Analysis", Proc. IEEE Int'l Conf. Face and
Gesture Recognition, 46-53, 2000. <br>
[6] Ekman, P., "Universals and cultural differences in facial expressions
of emotion", Nebr. Symp. Motiv. 1971, 207-283, 1972. <br>
[7] Pantic, M., et al., "Web-Based Database for Facial Expression
Analysis", Proc. ACM Int'l Conf. Multimedia, 317-321, 2005. <br>
[8] O'Toole, A.J., et al., "A Video Database of Moving Faces and
People". IEEE Trans. PAMI, 27(5):812-816, 2005. <br>
[9] Roisman, G.I., et al., "The Emotional Integration of Childhood
Experience: Physiological, Facial Expressive, and Self-Reported
Emotional Response during the Adult
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Attachment Interview", Developmental
Psychology, 40(5):776-789, 2004. <br>
[10] Douglas-Cowie, E., et al., "Emotional Speech: Towards a New
Generation of Database", Speech Communication, 40(1-2):33-60, 2003. <br>
[11] Busso, C. and Narayanan, S.S., "Interrelation Between Speech
and Facial Gestures in Emotional Utterances: A Single Subject
Study", IEEE Trans. ASLP, 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15(8):2331-2347, 2007. <br>
[12] Zeng, Z., Pantic, M., Roisman, G.I. and Huang, T.S., "Survey
of Affect Recognition Methods: Audio, Visual, and Spontaneous
Expressions", IEEE Trans. PAMI, 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;31(1):39-58, 2009. <br>
[13] 3dMD, "3dMD 4D Capture System", Online: http://
www.3dmd.com, accessed on 27 Apr 2010. <br>
[14] Young, S., et al., "Hidden Markov Model Toolkit",
Cambridge University Engineering Department, UK. Online:
http://htk.eng.cam.ac.uk/, accessed on 27 Apr 2010. <br>
[15] Huckvale, M., "Speech Filing System", UCL Dept. of Phonetics
&amp; Linguistics, UK. Online: http://www.phon.ucl.ac.uk/
resource/sfs/, accessed on 27 Apr 2010. <br>
[16] Swerts, M., et al., "Gender-related differences in the production
and perception of emotion", Proc. Interspeech, 334вЂ“337, 2008. <br>
[17] Edwards, A. L., "Experimental Design in Psychological Research",
New York: Holt, Rinehart and Winston, 1962. <br>
[18] Eyben, F., Woellmer, M. and Schuller, B., "openEAR - An introductory
tutorial", Institute for Human-Machine Communication,
Technische Universitaet Muenchen, 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Munich, Germany, 2009. <br>
[19] Lorenzo, M.L., et al., "Use and Re-use of Facial Motion Capture
Data", Proc. Vision, Video, and Graphics, 1-8, 2003. <br>
[20] Haq, S. and Jackson, P.J.B., "Speaker-Dependent Audio-Visual
Emotion Recognition", Proc. AVSP, 53-58, 2009. <br>
[21] Vlasenko, B., et al., "Combining Frame and Turn-Level Information
for Robust Recognition of Emotions within Speech", Proc.
Interspeech, 2249-2252, 2007.</p>

    
  <!-- InstanceEndEditable --></div>

  <div class="clear"></div>
</div>
<div id="footer" class="container_12 topborder">
  <div class="grid_6" style="text-align:left;"><a href="http://www.surrey.ac.uk/">University of Surrey</a> | 
<a href="http://www.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/Register.html">Register</a> | 
<a href="mailto:p.jackson@surrey.ac.uk?subject=SAVEE">Contact Us</a>
<!-- <a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/">Contact Us</a> -->
 </div>
</div>
<div id="credit" class="container_12">


  <!-- The following link and credit cannot legally be altered or removed without a valid website license key purchased from http://www.justdreamweaver.com/templates/license.html. License keys are only $19.99 and once purchased you are free to remove or alter the link. -->

<div class="grid_12">
Last update: 2 April 2015
<br>
Authors: Philip Jackson and Sanaul Haq
<br>
Designed by <a href="http://www.justdreamweaver.com/dreamweaver-templates.html" target="_blank">JustDreamweaver.com</a>

</div>
</div>

<!-- InstanceEnd -->
</body><div></div></html>